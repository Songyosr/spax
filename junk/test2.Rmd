---
title: "Test"
author: "Songyos Rajborirug (Tony)"
date: "2024-12-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Library/CloudStorage/OneDrive-JohnsHopkins/Education/thesis/R/ESRD")

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8, fig.height = 4.5,
  dpi = 100
)
```

# Lib

```{r}
# Load required libraries
library(raster)     # For legacy raster support
library(terra)      # For modern raster operations
library(tidyverse)  # For data manipulation
library(sf)         # For vector spatial data
library(sp)         # For vector spatial data
library(spax)       # For spatial accessibility analysis
library(foreach)
library(doParallel)
```


## Import

```{r}
# Mask
mask <- readRDS('data/r2/r2_mask.rds')

# Healthcare facility information (supply side)
hd <- readRDS('data/hd/vect/hd_info.rds')         
hd_iso <- readRDS('data/hd/vect/hd_isochrones_det4.rds') # Isochrones
#hd_iso$location_id <- factor(hd_iso$location_id, levels = unique(hd_iso$location_id))

# Population density (demand side)
pop_density <- readRDS('data/pop_dens/pop_cropped_10.rds')
```

```{r}
# Create a smaller version of the population density raster
tiny_pop_density <- (pop_density) |> 
  aggregate(fact = 5, fun = "sum", na.rm=TRUE, #method="simple", 
            progress = "text",# window=w,
            cores = 8) |> 
  terra::crop(vect(mask), mask = TRUE) 

# Convert the population density to expected dialysis density
dialysis_density <- tiny_pop_density * 2448 / 1000000 # 2448 dialysis patients per million populations
```

## 1. Supply-Side Data

Supply locations (in our case, dialysis centers) include:

-   Geographic coordinates: used to create the traveling time isochrones or distance

-   Capacity indicators such as: Number of dialysis machines, Staff availability

```{r}
hd <- hd |> 
  st_drop_geometry() |>
  select(location_id, 
         starts_with('s_'),  # Select columns starting with 's_' - supply indicators
         starts_with('hd_')) # Select columns starting with 'hd_' - Realized demand indicators

hd |> head()
```

```{r}
# Converted to a raster format for analysis
distance_raster <- fasterize::fasterize(hd_iso, 
                  tiny_pop_density|> raster(),   # Use the dialysis_density raster as a template
                  field = "iso_mean", # Fill the raster with the iso_mean values
                  background = NA,
                  fun = "sum",
                  #na.rm = TRUE,
                  by = "location_id") |> rast() |>
  terra::crop(vect(mask), mask = TRUE)
```

```{r}
# system.time({
# tuning_results <- tune_decay_params(
#   distance_raster = distance_raster,
#   demand_raster = dialysis_density,
#   supply = hd$s_rounds_per_week,
#   observed = hd$hd_patients_total,
#   sigma_range = seq(5, 10, by = 1),
#   a0_range = seq(0.005, 0.007, by = 0.0001),
#   debug = T
# )
# })
```

```{r}

```


```{r}
system.time({
tuning_results <- tune_decay_params(
  distance_raster = distance_raster,
  demand_raster = dialysis_density,
  supply = hd$s_rounds_per_week,
  observed = hd$hd_patients_total,
  sigma_range = seq(7, 8, by = 0.1),
  a0_range = seq(0.007, 0.021, by = 0.001),
  debug = F
)
})
# Plot results
```


```{r}
ybar <- hd$hd_patients_total 

p2 <- ggplot(tuning_results$results, aes(x = sigma, y = a0)) +
    geom_tile(aes(
      fill = rmse#log(rmse/ybar)
      )) +
    scale_fill_viridis_c(option = "plasma") +
    labs(title = "Parameter Space",
         x = "Sigma (Distance Decay)",
         y = "A0 (No-Care Threshold)") +
    theme_minimal()

p2
#p1
```


```{r}
best_rmse <- min(tuning_results$results$rmse)

best_correlation <- max(tuning_results$results$correlation)

filtered_results <- tuning_results$results |> 
  filter( correlation == best_correlation | rmse == best_rmse) |> 
  select(sigma, a0, rmse, correlation)

filtered_results

```


```{r}
# best_idx <- which.max(results$results$rmse)
  # best_params <- results$results[best_idx,]
  # best_pred <- results$predictions[best_idx,]
  # 
  # p2 <- ggplot(data.frame(Observed = observed, Predicted = best_pred),
  #              aes(x = Observed, y = Predicted)) +
  #   geom_point() +
  #   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  #   labs(title = sprintf("Best Fit\nσ=%.1f, A0=%.2f",
  #                        best_params$sigma,
  #                        best_params$a0)) +
  #   theme_minimal()
  # 
  # gridExtra::grid.arrange(p1, p2, ncol = 2)

```

```{r}
test_fit <- calc_params_fit(
  sigma = 7.5,
  a0 = 0.005,
  distance_raster = distance_raster,
  demand_raster = dialysis_density, 
  supply = hd$s_rounds_per_week,
  observed = hd$hd_patients_total,
  debug = TRUE
)

test_fit$compare

with(test_fit$compare, {
  sum(dpois(observed, predicted, log = TRUE))
})

#sum(dpois(observed, predicted, log = TRUE)
# 
# 
# res(distance_raster)
# res(dialysis_density)
```

```{r}
# Run parallel optimization with multiple starting points
system.time({
  optim_results <- tune_decay_params_optim_parallel(
    distance_raster = distance_raster,
    demand_raster = dialysis_density,
    supply = hd$s_rounds_per_week,
    observed = hd$hd_patients_total,
    lower = c(sigma = 1, a0 = 0.001),
    upper = c(sigma = 30, a0 = 0.010),
    n_starts = 8,  # Number of random starting points
    debug = TRUE
  )
})

# Look at results
print("Best parameters found:")
print(optim_results$best_fit$parameters)
print("\nSummary of all optimization runs:")
print(summary(optim_results$all_results))

# Plot results
plot_optim_results(optim_results)

optim_results$best_fit
plot(optim_results$best_fit$predicted, observed,
       xlab = "Predicted", ylab = "Observed",
       main = paste("Best Fit\nR =",
                    round(results$best_fit$correlation, 3)))
  abline(0, 1, col = "red", lty = 2)

?plot_optim_results

```

# Junp here

```{r}
# optim_results <- tune_decay_params_optim(
#   distance_raster = distance_raster,
#   demand_raster = dialysis_density,
#   supply = hd$s_rounds_per_week,
#   observed = hd$hd_patients_total,
#   init_params = c(sigma = 10, a0 = 0.01),  # Start with small a0
#   lower = c(sigma = 1, a0 = 0.001),       # Much smaller lower bound for a0
#   upper = c(sigma = 50, a0 = 0.1),        # Much smaller upper bound for a0
#   debug = TRUE
# )
# 
# optim_results


```


# test 


```{r}
# Benchmarking different approaches to PMF sampling
# Requires: terra, microbenchmark, tidyverse

library(terra)
library(microbenchmark)
library(tidyverse)

# Helper functions for the two approaches
sample_pmf_rasterize <- function(x, n_samples, template) {
    points <- spatSample(x, size = n_samples, method = "weights", as.points = TRUE)
    rasterize(points, template, fun = "count")
}

sample_pmf_direct <- function(x, n_samples, template) {
    r <- rast(template)
    values(r) <- 0  # Initialize empty raster
    # Get cell numbers directly
    sampled_cells <- spatSample(x, size = n_samples, 
                               method = "weights", 
                               cells = TRUE)$cell
    # Increment the counts
    values(r)[sampled_cells] <- values(r)[sampled_cells] + 1
    r
}

# # sample_pmf_direct(tiny_pop_density, 15, tiny_pop_density)
# # spatSample(x, size = n_samples, method = "weights")
# testt <- spatSample(tiny_pop_density, size = 15, 
#                     method = "weights",
#                     cell = T,
#                     values = F)
```


```{r}
testt
#values(tiny_pop_density)
```


```{r}
# # Create test data of different sizes
# create_test_raster <- function(size) {
#     r <- rast(nrows = size, ncols = size)
#     values(r) <- runif(ncell(r))
#     r <- r / global(r, "sum", na.rm = TRUE)$sum  # Convert to PMF
#     return(r)
# }
# 
# # Benchmark parameters
# raster_sizes <- c(100, 500, 1000)  # Different raster dimensions
# sample_sizes <- c(100, 1000, 10000)  # Different numbers of points to sample
```

```{r}
# Create test raster function
create_test_raster <- function(size) {
    r <- rast(nrows = size, ncols = size)
    values(r) <- runif(ncell(r))
    r <- r / global(r, "sum", na.rm = TRUE)$sum  # Convert to PMF
    return(r)
}

# Create test scenarios
scenarios <- expand_grid(
    raster_size = c(300,700, 1500),
    sample_size = c(800, 8000)
) |>
    mutate(
        test_raster = map(raster_size, create_test_raster)
    )

```

# Run benc
```{r}
# Run benchmarks
benchmark_results <- scenarios %>%
    mutate(
        benchmark = pmap(list(test_raster, sample_size, test_raster), 
            function(rast, size, template) {
                microbenchmark(
                    rasterize = sample_pmf_rasterize(rast, size, template),
                    direct = sample_pmf_direct(rast, size, template),
                    times = 10
                )
            })
    ) %>%
    select(-test_raster) %>%  # Remove the raster objects
    unnest(benchmark) %>%
    mutate(time = time / 1e9)  # Convert to seconds
```

#summ
```{r}
# Summarize results
summary_stats <- benchmark_results %>%
    group_by(raster_size, sample_size, expr) %>%
    summarise(
        mean_time = mean(time),
        sd_time = sd(time),
        median_time = median(time),
        .groups = 'drop'
    )

# Plot results
ggplot(summary_stats, 
       aes(x = factor(sample_size), y = mean_time, 
           fill = expr, group = expr)) +
    geom_bar(stat = "identity", position = "dodge") +
    geom_errorbar(aes(ymin = mean_time - sd_time, 
                     ymax = mean_time + sd_time),
                 position = position_dodge(0.9), width = 0.25) +
    facet_wrap(~raster_size, scales = "free_y",
              labeller = labeller(raster_size = 
                                  function(x) paste0("Raster: ", x, "x", x))) +
    labs(x = "Sample Size",
         y = "Time (seconds)",
         title = "Performance Comparison of PMF Sampling Methods",
         subtitle = "Error bars show ±1 SD") +
    theme_minimal()

# Print detailed summary
print(summary_stats %>%
        arrange(raster_size, sample_size, expr))
```

```{r}
sample_pmf_optimized2 <- function(x, iterations, lambda, template) {
    # 1. Get sample sizes for all iterations at once
    n_samples <- rpois(iterations, lambda)
    total_n <- sum(n_samples)
    
    # 2. Create empty multi-layer template 
    result <- rast(template, nlyrs = iterations)
    values(result) <- 0
    
    # 3. Do one large sampling
    cells <- spatSample(x, size = total_n, method = "weights", cells = TRUE)$cell
    
    # 4. Create layer indices based on sample sizes
    layer_indices <- rep(1:iterations, times = n_samples)
    
    # 5. Create indexing matrix for all points at once
    idx <- cbind(cells, layer_indices)
    
    # 6. Fill all values in one operation
    values(result)[idx] <- 1
    
    return(result)
}
```

# TEst for best repeat sample
```{r}
# Benchmark different approaches to PMF sampling
library(terra)
library(microbenchmark)
library(tidyverse)

# Original approach - separate sampling for each realization
sample_pmf_original <- function(x, iterations, lambda, template) {
    replicate(iterations, {
        n <- rpois(1, lambda)
        cells <- spatSample(x, size = n, method = "weights", cells = TRUE)$cell
        r <- rast(template)
        values(r) <- 0
        values(r)[cells] <- 1
        r
    }, simplify = FALSE) |>
    rast()
}

# Optimized - one large sampling, split into layers with loop
sample_pmf_opt1 <- function(x, iterations, lambda, template) {
    n_samples <- rpois(iterations, lambda)
    total_n <- sum(n_samples)
    
    result <- rast(template, nlyrs = iterations)
    values(result) <- 0
    
    cells <- spatSample(x, size = total_n, method = "weights", cells = TRUE)$cell
    layer_indices <- rep(1:iterations, times = n_samples)
    
    # Use sapply instead of for loop
    sapply(1:iterations, function(i) {
        layer_cells <- cells[layer_indices == i]
        values(result)[cbind(layer_cells, rep(i, length(layer_cells)))] <- 1
    })
    
    result
}

# Fully vectorized - one large sampling, one assignment
sample_pmf_opt2 <- function(x, iterations, lambda, template) {
    n_samples <- rpois(iterations, lambda)
    total_n <- sum(n_samples)
    
    result <- rast(template, nlyrs = iterations)
    values(result) <- 0
    
    cells <- spatSample(x, size = total_n, method = "weights", cells = TRUE)$cell
    layer_indices <- rep(1:iterations, times = n_samples)
    
    idx <- cbind(cells, layer_indices)
    values(result)[idx] <- 1
    
    result
}
```


```{r}
# Create test data
create_test_pmf <- function(size) {
    r <- rast(nrows = size, ncols = size)
    values(r) <- runif(ncell(r))
    r <- r / global(r, "sum", na.rm = TRUE)$sum
    return(r)
}

# Test scenarios
scenarios <- expand_grid(
    raster_size = c(100, 300),  # Raster dimensions
    iterations = c(10, 50),     # Number of realizations
    lambda = c(100, 500)        # Expected number of points per realization
) |>
    mutate(
        test_raster = map(raster_size, create_test_pmf)
    )

# Run benchmarks
benchmark_results <- scenarios |>
    mutate(
        benchmark = pmap(list(test_raster, iterations, lambda, test_raster), 
            function(rast, iter, lam, template) {
                microbenchmark(
                    original = sample_pmf_original(rast, iter, lam, template),
                    optimized_1 = sample_pmf_opt1(rast, iter, lam, template),
                    optimized_2 = sample_pmf_opt2(rast, iter, lam, template),
                    times = 5
                )
            })
    ) |>
    select(-test_raster) |>
    unnest(benchmark) |>
    mutate(time = time / 1e9)  # Convert to seconds

# Summarize results
summary_stats <- benchmark_results |>
    group_by(raster_size, iterations, lambda, expr) |>
    summarise(
        mean_time = mean(time),
        sd_time = sd(time),
        median_time = median(time),
        .groups = 'drop'
    )

# Plot results
ggplot(summary_stats, 
       aes(x = interaction(iterations, lambda), y = mean_time, 
           fill = expr, group = expr)) +
    geom_bar(stat = "identity", position = "dodge") +
    geom_errorbar(aes(ymin = mean_time - sd_time, 
                     ymax = mean_time + sd_time),
                 position = position_dodge(0.9), width = 0.25) +
    facet_wrap(~raster_size, scales = "free_y",
              labeller = labeller(raster_size = 
                                  function(x) paste0("Raster: ", x, "x", x))) +
    labs(x = "Iterations x Lambda",
         y = "Time (seconds)",
         title = "Performance Comparison of PMF Sampling Methods",
         subtitle = "Error bars show ±1 SD") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print detailed summary
print(summary_stats |>
        arrange(raster_size, iterations, lambda, expr))
```

